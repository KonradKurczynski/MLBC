---
title: "CEO Time Use and Firm Performance: A Topic Model Application"
output: 
  md_document:
    variant: gfm
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  warning = FALSE,
  message = FALSE
)
```

```{r}
library(MLBC)
```

# About this notebook

This notebook estimates the association between CEO time alocation and firm performance [(Bandiera et al. 2020)](https://www.journals.uchicago.edu/doi/10.1086/705331). It illustrates how the functions `ols_bca_topic` and `ols_bcm_topic` can be used to correct bias 
from estimated topic model shares. The notebook reproduces results from Table 2 of [Battaglia, Christensen, Hansen & Sacher (2024)](https://arxiv.org/abs/2402.15585). 

[(Bandiera et al. 2020)](https://www.journals.uchicago.edu/doi/10.1086/705331) conduct a time-use survey for a sample of CEOs. Survey responses are recorded for each 15-minute interval of a given week. The sample consists of 654 answer combinations. To reduce dimensionality, the authors fit a topic model with two topics. One topic
places relatively higher mass on features associated with "management," like visiting production sites or meeting with suppliers, while the other places relatively higher mass on features associated with "leadership" like communicating
with other C-suite executives and holding large, multi-function meetings.

Each CEO's leadership weight is a measure of their tendency to engage in leadership activities. One of the key results in [(Bandiera et al. 2020)](https://www.journals.uchicago.edu/doi/10.1086/705331) is a regression of log sales, a measure of firm size,
on the estimated leadership weight (along with other firm controls).


## Data

The package contains `topic_model_data`, which we will use for the regression as well as joint estimates of the regression and topic model, as described in [Battaglia, Christensen, Hansen & Sacher (2024)](https://arxiv.org/abs/2402.15585).

```{r}
# Load the topic model data
data("topic_model_data")


# Extract components
Z <- as.matrix(topic_model_data$covars)              # Control variables
estimation_data <- topic_model_data$estimation_data   # Main dataset  
gamma_draws <- as.matrix(topic_model_data$gamma_draws) # MCMC draws
theta_est_full <- as.matrix(topic_model_data$theta_est_full)   # Full sample topic estimates
theta_est_samp <- as.matrix(topic_model_data$theta_est_samp)   # Subsample topic estimates
beta_est_full <- as.matrix(topic_model_data$beta_est_full)     # Full sample topic-word distributions
beta_est_samp <- as.matrix(topic_model_data$beta_est_samp)     # Subsample topic-word distributions
lda_data <- as.matrix(topic_model_data$lda_data)      # LDA validation data

# Dependent variable: log employment, country fixed effects, and survey-wave fixed effects
Y <- estimation_data$ly
sigma_y <- sd(Y)

# Show sample of the data
sample_data <- data.frame(
  Y = Y,
  theta_topic1 = theta_est_full[, 1], 
  control1 = Z[, 1], 
  control2 = Z[, 2]
)
head(sample_data)
```

Here, `theta_topic1` contains the leadership topic weight for each observation.

# Results
We first present results for an OLS regression of log sales on the leadership topic weight and controls:

```{r}
# Full sample two-step estimation
theta_full <- theta_est_full
Xhat_full <- cbind(theta_full[, 1], Z)  # First topic + controls
lm_full <- ols(Y, Xhat_full, se = TRUE, intercept = TRUE)
summary(lm_full)
```
We now compare these estimates with bias-corrected estimates. We will use `ols_bca_topic`. This requires an estimate of $\kappa$, which is $\sqrt{n}E[C_{i}^{-1}]$, where $C_i$
is the number of feature counts in unstructured document $i$. This is stored in the first column of `lda_data`.

## Bias Correction

The empirical analogue of this expression is **θ̂ᵢ** for the simple model. While not directly applicable here as the topic model structure is more complex, it still allows one to qualitatively compare sampling error (reflected by **ζ̂ⱼ⁻¹**) and measurement error (reflected by **ε̂ [ζ̂ⱼ⁻¹]**). The empirical analogue of this expression is 0.44.

```{r}
# Full sample bias correction
kappa_full <- mean(1.0 / lda_data[, 1]) * sqrt(nrow(lda_data))
print(c("Kappa: ", kappa_full))
```

In addition to $\kappa$, we need to construct a matrix `S` which picks off the relevant column of `theta_full` (a `n` by `K` matrix, `K` being the number of topics, here `K = 2`) to include in the regression.

We also include the estmated topic-word distributions (a `V` by `K` matrix, ` V` being the number of features in the otpic model). 
```{r}
S <- matrix(c(1.0, 0.0), nrow = 1)  # Topic loadings: first topic active

bc_full <- ols_bca_topic(Y = Y,
                         Q = Z,                    # Control variables  
                         W = theta_est_full,       # Document-topic proportions
                         S = S,                    # Topic loadings
                         B = beta_est_full,        # Topic-word distributions
                         k = kappa_full)           # Scaling parameter
summary(bc_full)
```
The two methods (`ols` and `ols_bca_topic`) produce similar estimates and confidence intervals. This suggests that measurement error in the estimated topic_1 shares
is small enough that it doesn't materially distort inference.

To explore this further, we repeat the above taking a 10% subsample of the data used to estimate the topic model. This ensures that the estimated topic weights are noisier
signals of the true leadership index. Here we are running the same regression as before, just with a noisier vvalue of the topic_1 weight.

The data are names as before, with a `_samp` suffix. 

```{r}
# 10% Subsample two-step estimation  
theta_samp <- theta_est_samp
Xhat_samp <- cbind(theta_samp[, 1], Z)
lm_samp <- ols(Y, Xhat_samp, se = TRUE, intercept = TRUE)
summary(lm_samp)
```
Evidently, increasing the measurement error in the estimated topic weights reduces the estimated slope coefficient by around 50%. Moreover, OLS confidence
intervals for the slope coefficient now include zero. 

We now compare with bias correction: 

```{r}
# 10% Subsample bias correction
kappa_samp <- mean(1.0 / lda_data[, 2]) * sqrt(nrow(lda_data))

bc_samp <- ols_bca_topic(Y = Y,
                         Q = Z,
                         W = theta_est_samp,
                         S = S, 
                         B = beta_est_samp,
                         k = kappa_samp)
summary(bc_samp)
```

Performing the bias correction results in a much larger estimated effect size. 

Finally, we tabulate the results from the joint estimation performed by [Battaglia, Christensen, Hansen & Sacher (2024)](https://arxiv.org/abs/2402.15585):

```{r}
# Joint estimation using MCMC draws (scaled by dependent variable standard deviation)
gamma_scaled <- gamma_draws * sigma_y
gamma_hat_1 <- colMeans(gamma_scaled)

# Calculate empirical confidence intervals from MCMC draws
alpha <- 0.05
ci_lower_1 <- apply(gamma_scaled, 2, quantile, probs = alpha/2)
ci_upper_1 <- apply(gamma_scaled, 2, quantile, probs = 1 - alpha/2)

cat("Joint estimates and confidence intervals:\n")
cat("Full Sample:", round(gamma_hat_1[1], 3), 
    " [", round(ci_lower_1[1], 3), ",", round(ci_upper_1[1], 3), "]\n")
cat("10% Subsample:", round(gamma_hat_1[2], 3),
    " [", round(ci_lower_1[2], 3), ",", round(ci_upper_1[2], 3), "]\n")
```

We see that unlike OLS estimation, joint estimation is robust to increasing the noise in the estimated topic weight. Both samples produce a similar estimated effect size onfidence intervals that 
exclude zero. 

Finally, we tabulate all results together: 
```{r}
# Extract key coefficients for the first topic (management)
results <- data.frame(
  Sample = c("Full", "10% Subsample", "Full", "10% Subsample", "Full"),
  Method = c("Two-Step", "Two-Step", "Bias Correction", "Bias Correction", "Joint"),
  Estimate = c(lm_full$coef[1],
               lm_samp$coef[1], 
               bc_full$coef[1],
               bc_samp$coef[1],
               gamma_hat_1[1]),
  CI_Lower = c(lm_full$coef[1] - 1.96 * sqrt(lm_full$vcov[1,1]),
               lm_samp$coef[1] - 1.96 * sqrt(lm_samp$vcov[1,1]),
               bc_full$coef[1] - 1.96 * sqrt(bc_full$vcov[1,1]),
               bc_samp$coef[1] - 1.96 * sqrt(bc_samp$vcov[1,1]),
               ci_lower_1[1]),
  CI_Upper = c(lm_full$coef[1] + 1.96 * sqrt(lm_full$vcov[1,1]),
               lm_samp$coef[1] + 1.96 * sqrt(lm_samp$vcov[1,1]),
               bc_full$coef[1] + 1.96 * sqrt(bc_full$vcov[1,1]),
               bc_samp$coef[1] + 1.96 * sqrt(bc_samp$vcov[1,1]),
               ci_upper_1[1])
)

results$Estimate <- round(results$Estimate, 3)
results$CI_Lower <- round(results$CI_Lower, 3)
results$CI_Upper <- round(results$CI_Upper, 3)

print(results)
```

```{r, fig.width=8, fig.height=5}
if (require(ggplot2, quietly = TRUE)) {
  plot_data <- results
  plot_data$Method_Sample <- paste(plot_data$Method, "(", plot_data$Sample, ")")
  plot_data$Type <- ifelse(plot_data$Method == "Two-Step", "Two-Step",
                   ifelse(plot_data$Method == "Bias Correction", "Bias Correction", "Joint"))
  
  p <- ggplot(plot_data, aes(x = reorder(Method_Sample, Estimate), y = Estimate, color = Type)) +
    geom_point(size = 3) +
    geom_errorbar(aes(ymin = CI_Lower, ymax = CI_Upper), width = 0.3, size = 1) +
    geom_hline(yintercept = 0, linetype = "dashed", alpha = 0.5) +
    coord_flip() +
    theme_minimal() +
    theme(
      legend.position = "bottom",
      panel.grid.minor = element_blank(),
      plot.title = element_text(size = 12, face = "bold"),
      plot.subtitle = element_text(size = 10)
    ) +
    labs(
      title = "Estimates of Impact of CEO Behavior on Firm Performance",
      subtitle = "Comparison of estimation strategies with 95% confidence intervals",
      x = "Estimation Strategy",
      y = "Coefficient Estimate",
      color = "Method Type"
    ) +
    scale_color_manual(values = c("Two-Step" = "#56B4E9", 
                                 "Bias Correction" = "#009E73",
                                 "Joint" = "#E69F00"))
  
  print(p)
} else {
  cat("ggplot2 not available for plotting\n")
}
```


